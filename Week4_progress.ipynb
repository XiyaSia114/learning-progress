{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93793302-c215-4877-91fd-feaa108cf329",
   "metadata": {},
   "source": [
    "# 本周学习总结\n",
    "\n",
    "## 学习周期\n",
    "**周次**：第4周  \n",
    "**学习内容**：Introduction to Economic Modeling and Data Science\n",
    " -    DataFrames and Series in Pandas             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bc752-c264-449b-a306-640574ec18fb",
   "metadata": {},
   "source": [
    "## DataFrames and Series in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d36ec-f343-4d46-a933-7f1aa70a181c",
   "metadata": {},
   "source": [
    "### The Index\n",
    "- **Index对象**：类似数组但不可变，支持集合运算\n",
    "-  **`.reindex()`**  ：重新排列、插入或删除数据\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# 创建Series并查看index\n",
    "data = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(data.index)  # Index(['a', 'b', 'c'], dtype='object')\n",
    "\n",
    "# reindex操作\n",
    "new_index = ['c', 'b', 'a', 'd']\n",
    "reindexed = data.reindex(new_index)\n",
    "print(reindexed)\n",
    "```\n",
    "**MultiIndex（多级索引）**\n",
    "- 在**DataFrame**行或列上创建层次化索引\n",
    "- 支持更复杂的数据组织方式\n",
    "\n",
    "```python\n",
    "# 创建MultiIndex示例\n",
    "multi_idx = pd.MultiIndex.from_tuples([\n",
    "    ('A', 1), ('A', 2), ('B', 1), ('B', 2)\n",
    "], names=['Letter', 'Number'])\n",
    "\n",
    "df_multi = pd.DataFrame({'Values': [10, 20, 30, 40]}, index=multi_idx)\n",
    "print(df_multi)\n",
    "\n",
    "# MultiIndex索引\n",
    "print(df_multi.loc['A'])        # 选择第一层索引\n",
    "print(df_multi.loc[('A', 1)])   # 选择具体组合\n",
    "```\n",
    " **Index性能**\n",
    "- Index加速数据查找（基于哈希表）\n",
    "- 无Index的DataFrame使用逐行扫描（慢）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae220f42-ba75-47bf-a43e-cb4ddc167900",
   "metadata": {},
   "source": [
    "### Storage Formats\n",
    "#### **CSV文件**\n",
    "-  `.read_csv()`  : 读取CSV\n",
    "-  `.to_csv()`  : 写入CSV\n",
    "-  **注意**  ：CSV不保存**index**和**data types**\n",
    "\n",
    "```python\n",
    "# 读取CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# 写入CSV（不保存index）\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# 读取时指定index列\n",
    "df_indexed = pd.read_csv('data.csv', index_col='date')\n",
    "```\n",
    "\n",
    "#### **Excel文件**\n",
    "-  `.read_excel()`  : 读取Excel\n",
    "-  `.to_excel()`  : 写入Excel\n",
    "-  **安装**  ：需要`openpyxl`库\n",
    "\n",
    "```python\n",
    "# 读取Excel（指定sheet）\n",
    "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 写入Excel（多个sheet）\n",
    "with pd.ExcelWriter('output.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Data1')\n",
    "    df2.to_excel(writer, sheet_name='Data2')\n",
    "```\n",
    "\n",
    "#### **HDF5格式**\n",
    "- 高性能二进制格式，支持大文件\n",
    "-  `.read_hdf()`  和 `.to_hdf()`\n",
    "- 支持**query**和**chunked reading**\n",
    "\n",
    "```python\n",
    "# 写入HDF5\n",
    "df.to_hdf('data.h5', key='df', mode='w')\n",
    "\n",
    "# 读取HDF5（支持query）\n",
    "large_df = pd.read_hdf('data.h5', key='df', where='column > 10')\n",
    "```\n",
    "\n",
    "#### **Parquet格式**\n",
    "- 列式存储，压缩高效\n",
    "-  `.read_parquet()`  和 `.to_parquet()`\n",
    "- 支持复杂**data types**\n",
    "\n",
    "```python\n",
    "# 写入Parquet\n",
    "df.to_parquet('data.parquet')\n",
    "\n",
    "# 读取Parquet\n",
    "df = pd.read_parquet('data.parquet')\n",
    "```\n",
    "\n",
    "#### **Pickle格式**\n",
    "- 保存完整Python对象（包括types和functions）\n",
    "- 仅用于**可信数据**（安全风险）\n",
    "\n",
    "```python\n",
    "# 写入Pickle\n",
    "df.to_pickle('data.pkl')\n",
    "\n",
    "# 读取Pickle\n",
    "df = pd.read_pickle('data.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba66cdd-8293-43a1-9867-5b6d6cc528b8",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "#### **缺失值处理（Missing Values）**\n",
    "-  `.isna()`  : 检测缺失值\n",
    "-  `.dropna()`  : 删除含缺失值的行/列\n",
    "-  `.fillna()`  : 填充缺失值\n",
    "\n",
    "```python\n",
    "# 检测缺失值\n",
    "missing_mask = df.isna()\n",
    "print(missing_mask.sum())  # 每列缺失值数量\n",
    "\n",
    "# 删除缺失值\n",
    "df_cleaned = df.dropna()  # 删除任何含缺失值的行\n",
    "df_column_cleaned = df.dropna(subset=['important_col'])  # 仅删除特定列缺失的行\n",
    "\n",
    "# 填充缺失值\n",
    "df_filled = df.fillna(0)  # 用0填充\n",
    "df_filled_mean = df.fillna(df.mean())  # 用均值填充\n",
    "\n",
    "# 前向填充（ffill）\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "```\n",
    "\n",
    "#### **重复值处理（Duplicates）**\n",
    "-  `.duplicated()`  : 检测重复行\n",
    "-  `.drop_duplicates()`  : 删除重复行\n",
    "\n",
    "```python\n",
    "# 检测重复值\n",
    "duplicates = df.duplicated()\n",
    "print(f\"重复行数: {duplicates.sum()}\")\n",
    "\n",
    "# 删除重复值（保留首次出现）\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "# 删除特定列的重复值\n",
    "df_unique_subset = df.drop_duplicates(subset=['id'])\n",
    "```\n",
    "\n",
    "#### **异常值处理（Outliers）**\n",
    "- 使用统计方法或IQR规则识别\n",
    "- 替换或删除异常值\n",
    "\n",
    "```python\n",
    "# 使用IQR方法检测异常值\n",
    "Q1 = df['value'].quantile(0.25)\n",
    "Q3 = df['value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 异常值mask\n",
    "outlier_mask = (df['value'] < Q1 - 1.5 * IQR) | (df['value'] > Q3 + 1.5 * IQR)\n",
    "\n",
    "# 处理异常值（替换为边界值）\n",
    "df['value_cleaned'] = df['value'].clip(lower=Q1 - 1.5 * IQR, upper=Q3 + 1.5 * IQR)\n",
    "```\n",
    "\n",
    "#### **数据类型转换（Type Conversion）**\n",
    "-  `.astype()`  : 转换dtype\n",
    "-  `.to_numeric()`  : 强制转换为数值\n",
    "\n",
    "```python\n",
    "# 转换数据类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')  # 无效值转为NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e2454-2fa0-4b79-b2d4-7c081de8d252",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "#### **Pivot（长→宽）**\n",
    "-  `.pivot()`  : 长格式转为宽格式\n",
    "-  `.pivot_table()`  : 支持聚合的pivot\n",
    "\n",
    "```python\n",
    "# 长格式数据\n",
    "long_data = pd.DataFrame({\n",
    "    'date': ['2020-01', '2020-01', '2020-02', '2020-02'],\n",
    "    'variable': ['A', 'B', 'A', 'B'],\n",
    "    'value': [10, 15, 12, 18]\n",
    "})\n",
    "\n",
    "# Pivot为宽格式\n",
    "wide_data = long_data.pivot(index='date', columns='variable', values='value')\n",
    "print(wide_data)\n",
    "\n",
    "# Pivot table（带聚合）\n",
    "pivot_table = long_data.pivot_table(\n",
    "    index='date', columns='variable', values='value', aggfunc='mean'\n",
    ")\n",
    "```\n",
    "\n",
    "#### **Melt（宽→长）**\n",
    "-  `.melt()`  : 宽格式转为长格式\n",
    "\n",
    "```python\n",
    "# 宽格式数据\n",
    "wide_data = pd.DataFrame({\n",
    "    'date': ['2020-01', '2020-02'],\n",
    "    'A': [10, 12],\n",
    "    'B': [15, 18]\n",
    "})\n",
    "\n",
    "# Melt为长格式\n",
    "long_data = wide_data.melt(id_vars='date', var_name='variable', value_name='value')\n",
    "print(long_data)\n",
    "```\n",
    "\n",
    "#### **Stack和Unstack**\n",
    "-  `.stack()`  : 将columns压缩到index（宽→长）\n",
    "-  `.unstack()`  : 将index展开为columns（长→宽）\n",
    "\n",
    "```python\n",
    "# 创建MultiIndex DataFrame\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(4, 2),\n",
    "    index=pd.MultiIndex.from_product([['A', 'B'], [1, 2]]),\n",
    "    columns=['X', 'Y']\n",
    ")\n",
    "\n",
    "# Stack操作\n",
    "stacked = df.stack()\n",
    "print(stacked)\n",
    "\n",
    "# Unstack操作\n",
    "unstacked = stacked.unstack()\n",
    "print(unstacked)\n",
    "\n",
    "# 指定unstack level\n",
    "unstacked_level0 = stacked.unstack(level=0)  # unstack第一层index\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ebb572-b036-407f-9270-d1e3c799ed50",
   "metadata": {},
   "source": [
    "### Merge\n",
    "#### **Concat（连接）**\n",
    "- 沿行或列方向连接\n",
    "-  `axis=0`  : 垂直连接（增加行）\n",
    "-  `axis=1`  : 水平连接（增加列）\n",
    "\n",
    "```python\n",
    "# 垂直连接\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "concat_vert = pd.concat([df1, df2])  # 默认axis=0\n",
    "\n",
    "# 水平连接\n",
    "df3 = pd.DataFrame({'C': [9, 10], 'D': [11, 12]})\n",
    "concat_horiz = pd.concat([df1, df3], axis=1)\n",
    "```\n",
    "\n",
    "#### **Merge（合并）**\n",
    "- 基于列值匹配合并\n",
    "-  `how`  : `inner`（默认）、`left`、`right`、`outer`\n",
    "-  `on`  : 指定匹配的列\n",
    "\n",
    "```python\n",
    "# 创建DataFrame\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n",
    "\n",
    "# Inner merge（默认）\n",
    "merged_inner = pd.merge(df1, df2, on='key')\n",
    "print(merged_inner)  # 仅保留key为A,B的行\n",
    "\n",
    "# Outer merge（保留所有key）\n",
    "merged_outer = pd.merge(df1, df2, on='key', how='outer')\n",
    "print(merged_outer)  # 包含A,B,C,D，缺失值用NaN填充\n",
    "\n",
    "# Left merge（保留左表所有行）\n",
    "merged_left = pd.merge(df1, df2, on='key', how='left')\n",
    "```\n",
    "\n",
    "#### **Join（连接）**\n",
    "- 基于index的连接\n",
    "- 类似merge但使用index作为key\n",
    "\n",
    "```python\n",
    "# 设置index\n",
    "df1_indexed = df1.set_index('key')\n",
    "df2_indexed = df2.set_index('key')\n",
    "\n",
    "# Join操作\n",
    "joined = df1_indexed.join(df2_indexed, how='inner')\n",
    "print(joined)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753440e-b06b-42f0-9678-fa1ff104634d",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "\n",
    "**核心概念**：使用**groupby**进行分组计算，生成**aggregations**、**transforms**、**filters**\n",
    "\n",
    "#### **分组聚合（Groupby Aggregation）**\n",
    "-  `.groupby()`  → **split**-apply-combine模式\n",
    "-  `.agg()`  : 对每个组应用聚合函数\n",
    "\n",
    "```python\n",
    "# 加载数据\n",
    "url = \"https://datascience.quantecon.org/assets/data/employment.csv\"\n",
    "emp = pd.read_csv(url)\n",
    "emp = emp.set_index('year')\n",
    "\n",
    "# 按行业和州分组，计算工资均值\n",
    "industry_state_means = emp.groupby(['industry', 'state'])['earnings'].mean()\n",
    "print(industry_state_means.head())\n",
    "\n",
    "# Reset index还原为多列DataFrame\n",
    "industry_state_means_df = industry_state_means.reset_index()\n",
    "```\n",
    "\n",
    "#### **多函数聚合**\n",
    "- 对同一列应用多个函数\n",
    "- 对不同列应用不同函数\n",
    "\n",
    "```python\n",
    "# 对一列应用多个函数\n",
    "multi_agg = emp.groupby('industry')['earnings'].agg(['mean', 'std', 'count'])\n",
    "print(multi_agg)\n",
    "\n",
    "# 对不同列应用不同函数\n",
    "custom_agg = emp.groupby('industry').agg({\n",
    "    'earnings': 'mean',\n",
    "    'age': ['min', 'max'],\n",
    "    'state': 'count'\n",
    "})\n",
    "print(custom_agg)\n",
    "```\n",
    "\n",
    "#### **分组转换（Groupby Transform）**\n",
    "- 计算组统计量并广播回原DataFrame\n",
    "- 保持原DataFrame形状\n",
    "\n",
    "```python\n",
    "# 计算行业平均工资并添加到原数据\n",
    "emp_copy = emp.copy()\n",
    "emp_copy['industry_avg_earnings'] = (\n",
    "    emp.groupby('industry')['earnings'].transform('mean')\n",
    ")\n",
    "print(emp_copy.head())\n",
    "\n",
    "# 计算行业平均工资的百分比\n",
    "emp_copy['earnings_vs_industry_avg'] = (\n",
    "    emp_copy['earnings'] / emp_copy['industry_avg_earnings']\n",
    ")\n",
    "```\n",
    "\n",
    "#### **分组过滤（Groupby Filter）**\n",
    "- 根据组属性筛选组\n",
    "\n",
    "```python\n",
    "# 保留样本数大于1000的行业\n",
    "large_industries = emp.groupby('industry').filter(\n",
    "    lambda x: len(x) > 1000\n",
    ")\n",
    "print(f\"保留行业数: {large_industries['industry'].nunique()}\")\n",
    "```\n",
    "\n",
    "#### **分组迭代（Groupby Iteration）**\n",
    "- 遍历每个组\n",
    "\n",
    "```python\n",
    "# 遍历每个行业组\n",
    "for industry_name, group in emp.groupby('industry'):\n",
    "    print(f\"行业: {industry_name}, 样本数: {len(group)}\")\n",
    "    if len(group) < 1000:\n",
    "        print(f\"  -> 样本太少，可能需要过滤\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f78579-bfea-4795-8c9a-a9c030505bfc",
   "metadata": {},
   "source": [
    "### Timeseries\n",
    "#### **Resample（重采样）**\n",
    "-  `.resample()`  : 改变时间序列频率\n",
    "-  `how`  : 聚合方法（`mean`, `sum`, `first`, `last`）\n",
    "\n",
    "```python\n",
    "# 加载数据\n",
    "url = \"https://datascience.quantecon.org/assets/data/employment.csv\"\n",
    "emp = pd.read_csv(url, parse_dates=['date'])\n",
    "emp = emp.set_index('date')[['earnings']]\n",
    "\n",
    "# 按年重采样\n",
    "yearly_means = emp.resample('Y').mean()\n",
    "print(yearly_means.head())\n",
    "\n",
    "# 按周重采样\n",
    "weekly_means = emp.resample('W').mean()\n",
    "print(weekly_means.head())\n",
    "```\n",
    "\n",
    "#### **Rolling（滚动窗口）**\n",
    "-  `.rolling()`  : 滚动窗口计算\n",
    "-  `.rolling(window).mean()`  : 移动平均\n",
    "\n",
    "```python\n",
    "# 计算30天移动平均\n",
    "rolling_mean = emp['earnings'].rolling(30).mean()\n",
    "print(rolling_mean.head(35))  # 前29个值为NaN（窗口不足）\n",
    "\n",
    "# 计算20天滚动标准差\n",
    "rolling_std = emp['earnings'].rolling(20).std()\n",
    "print(rolling_std.head(25))\n",
    "\n",
    "# 最小周期设置\n",
    "rolling_min10 = emp['earnings'].rolling(20, min_periods=10).mean()\n",
    "print(rolling_min10.head(15))  # 前10-19个值可用\n",
    "```\n",
    "\n",
    "#### **日期偏移（Date Offsets）**\n",
    "-  `pd.DateOffset`  : 灵活日期加减\n",
    "-  `+ pd.DateOffset(months=1)`  : 加一个月\n",
    "\n",
    "```python\n",
    "# 创建DatetimeIndex\n",
    "dates = pd.date_range('2020-01-31', periods=3, freq='M')\n",
    "\n",
    "# 加上一个月偏移\n",
    "offset_dates = dates + pd.DateOffset(months=1)\n",
    "print(offset_dates)\n",
    "\n",
    "# 使用offsets移动数据\n",
    "shifted = emp.shift(30)  # 向后移动30天\n",
    "print(shifted.head())\n",
    "```\n",
    "\n",
    "#### **时间差（Time Deltas）**\n",
    "-  `pd.Timedelta`  : 时间差对象\n",
    "- 支持天数、小时、分钟等单位\n",
    "\n",
    "```python\n",
    "# 创建时间差\n",
    "td = pd.Timedelta(days=7)\n",
    "print(td)\n",
    "\n",
    "# 计算时间差\n",
    "time_diff = emp.index[-1] - emp.index[0]\n",
    "print(f\"时间跨度: {time_diff.days}天\")\n",
    "\n",
    "# 筛选特定时间范围\n",
    "start_date = pd.Timestamp('2000-01-01')\n",
    "end_date = start_date + pd.Timedelta(days=365)\n",
    "year_data = emp.loc[start_date:end_date]\n",
    "print(year_data.shape)\n",
    "```\n",
    "\n",
    "#### **时间序列绘图**\n",
    "- 直接使用**DatetimeIndex**绘图，自动格式化x轴\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算原始数据和30天滚动平均\n",
    "ax = emp['earnings'].plot(label='Raw', alpha=0.5)\n",
    "emp['earnings'].rolling(30).mean().plot(ax=ax, label='30-day Rolling Mean')\n",
    "\n",
    "ax.set_ylabel('Earnings')\n",
    "ax.set_title('Earnings with Rolling Mean')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5cf63-77de-4052-8f2c-840d78f1e83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
